import json
import os
import threading
import time
from typing import Optional

import cv2
import numpy as np
import requests
import torch
from ultralytics import YOLO


from src.domain.ActionState import action_state
from src.domain.StreamCamState import StreamCamState
from src.domain.StreamState import StreamState
from src.mq.MQTTPublisher import create_default_publisher

try:
    publisher = create_default_publisher(brokers=["192.168.0.101"], topic="tony_one/cmd")

except Exception as e:
    print(e)

MODEL_PATH = r"src/yolo_model/yolov8s-worldv2.pt"


if not os.path.isfile(MODEL_PATH):
    raise FileNotFoundError(f"can not find file: {MODEL_PATH}")
print(f"loading model: {MODEL_PATH}")


DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"
yolo_model = YOLO(MODEL_PATH)


yolo_model.to(DEVICE)   #




# å›¾åƒå°ºå¯¸ï¼ˆå®½, é«˜ï¼‰
img_size = (640, 480)



FPS = 20
JPEG_QUALITY = 80

# MJPEG
Push_URL = "http://192.168.0.100:8000/push/detect_cam"


# ===============================pull  and push streaming ==================================
def get_opencv_frame(stream: StreamState):

    with stream._lock:
        if stream.latest_frame is None:
            return None

        jpg_bytes = stream.latest_frame

    # JPEG â†’ numpy array â†’ BGR
    nparr = np.frombuffer(jpg_bytes, np.uint8)
    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    return frame




# convert opencv frame to jpeg
def frame_to_jpeg(frame: Optional[np.ndarray], quality: int = 80) -> Optional[bytes]:

    if frame is None:
        return None

    ok, buf = cv2.imencode(".jpg", frame,
                           [int(cv2.IMWRITE_JPEG_QUALITY), quality])
    if not ok:
        return None

    return buf.tobytes()

def push_loop(state, url, name):

    session = requests.Session()
    frame_interval = 1.0 / FPS
    last_time = 0

    print(f"ğŸ“¡ video push thread start [{name}] â†’ {url}")

    while True:
        now = time.time()
        if now - last_time < frame_interval:
            time.sleep(0.001)
            continue
        last_time = now

        frame = state.get_frame_copy()
        if frame is None:
            time.sleep(0.05)
            continue

        ok, buf = cv2.imencode(".jpg", frame,
                               [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
        if not ok:
            print(f"âš ï¸ {name} JPEG encode fail")
            continue

        try:
            session.post(
                url,
                data=buf.tobytes(),
                headers={"Content-Type": "image/jpeg"},
                timeout=0.5
            )
        except Exception as e:
            print(f"âš ï¸ {name} æ¨æµå¼‚å¸¸: {e}")
            time.sleep(0.2)




IMG_SIZE = 640
CONF_THRES = 0.3
DEVICE = "0"

# ====================================detect object==========================================
def run_detect_script(pull_state:StreamState,is_yolo:bool):

    push_state = StreamCamState()
    t2 = threading.Thread(target=push_loop, args=(push_state, Push_URL, 'detect_cam'), daemon=True)
    t2.start()


    def detect_by_yolo(frame):
        detect_class = action_state.get_detect_class()

        if detect_class:
            yolo_model.set_classes(detect_class)
        # ç»Ÿä¸€èµ°å®‰å…¨è®¾ç½®é€»è¾‘


        results = yolo_model.predict(
            source=frame,
            imgsz=IMG_SIZE,
            conf=CONF_THRES,
            device=DEVICE,
            save=False,
            save_txt=False,
            verbose=False,
            show=False,

            max_det=20,
            agnostic_nms=False,
            vid_stride=1,
        )

        return  results

    try:
        while True:
            in_frame = get_opencv_frame(pull_state)
            if is_yolo:
                is_detect = action_state.get_start_detect()
                detect_class = action_state.get_detect_class()
                cls_len  = len(detect_class)
                # action_state.set_start_detect(True)
                if is_detect:
                    yolo_start = time.perf_counter()
                    res = detect_by_yolo(in_frame)
                    yolo_time = (time.perf_counter() - yolo_start) * 1000
                    # print(f"[YOLO] Inference time: {yolo_time:.2f} ms")

                    annotated = res[0].plot(conf=False)
                    push_state.latest_frame = annotated

                    # cv2.imshow("YOLO Stream", annotated)
                    # if cv2.waitKey(1) & 0xFF == ord('q'):
                    #     break
                else: push_state.latest_frame = in_frame

    except KeyboardInterrupt:
        print("\n[Main] Exit by user.")
    finally:

        cv2.destroyAllWindows()


def run_detect_script_new(pull_state: StreamState, is_yolo: bool):
    push_state = StreamCamState()
    t2 = threading.Thread(target=push_loop, args=(push_state, Push_URL, 'detect_cam'), daemon=True)
    t2.start()

    # ============ IoU è®¡ç®— ============
    def bbox_iou(box1, box2):
        """
        box: [x1, y1, x2, y2]
        """
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])

        inter_w = max(0.0, x2 - x1)
        inter_h = max(0.0, y2 - y1)
        inter = inter_w * inter_h

        area1 = max(0.0, box1[2] - box1[0]) * max(0.0, box1[3] - box1[1])
        area2 = max(0.0, box2[2] - box2[0]) * max(0.0, box2[3] - box2[1])

        union = area1 + area2 - inter + 1e-6
        return inter / union

    # ============ YOLO è°ƒç”¨ ============
    def detect_by_yolo(frame):
        detect_class = action_state.get_detect_class()
        if detect_class:
            yolo_model.set_classes(detect_class)

        results = yolo_model.predict(
            source=frame,
            imgsz=IMG_SIZE,
            conf=CONF_THRES,
            device=DEVICE,
            save=False,
            save_txt=False,
            verbose=False,
            show=False,
            max_det=20,
            agnostic_nms=False,
            vid_stride=1,
        )
        return results

    # ============ ç¨³å®šåˆ¤æ–­ç›¸å…³çŠ¶æ€ ============
    tracked_box = None      # å½“å‰è¿½è¸ªçš„æ¡†
    hit_count = 0           # å‘½ä¸­æ¬¡æ•°
    gap_count = 0           # è¿ç»­ miss å¸§æ•°

    IOU_THRESHOLD = 0.7
    MIN_HITS = 10            # å‘½ä¸­è¶³å¤Ÿå¤šæ¬¡è®¤ä¸ºç¨³å®š
    MAX_GAP = 5             # å…è®¸ä¸­é—´æ–­å‡ å¸§

    last_class_key = None   # ä¸Šä¸€æ¬¡çš„ detect_classï¼ˆtuple å½¢å¼ï¼‰
    stable_done = False     # è¿™ä¸€æ®µâ€œå•ç±»â€æ˜¯å¦å·²ç»ç¨³å®šè§¦å‘è¿‡ä¸€æ¬¡

    try:
        while True:
            in_frame = get_opencv_frame(pull_state)

            if is_yolo:
                is_detect = action_state.get_start_detect()
                detect_class = action_state.get_detect_class() or []  # list
                cls_len = len(detect_class)

                # å½“å‰ detect_class çš„â€œç­¾åâ€ï¼Œç”¨æ¥åˆ¤æ–­æ˜¯å¦å˜åŒ–
                class_key = tuple(detect_class) if detect_class else None

                # ========= åªè¦æ•°ç»„å†…å®¹å˜äº†ï¼Œå°±é‡ç½®ç¨³å®šé€»è¾‘ =========
                if class_key != last_class_key:
                    last_class_key = class_key
                    tracked_box = None
                    hit_count = 0
                    gap_count = 0
                    stable_done = False
                    try:
                        action_state.set_stable_detect(False)
                    except AttributeError:
                        pass

                if is_detect:
                    res = detect_by_yolo(in_frame)
                    boxes = res[0].boxes

                    # é»˜è®¤å½“å‰å¸§ä¸è§¦å‘ç¨³å®š
                    stable = False

                    # ========= åªåœ¨â€œæ£€æµ‹ç±»åˆ«æ•°é‡ == 1â€ æ—¶åšç¨³å®šåˆ¤æ–­ =========
                    if cls_len == 1 and not stable_done:
                        if boxes is not None and len(boxes) > 0:
                            # å–ç½®ä¿¡åº¦æœ€é«˜çš„æ¡†
                            confs = boxes.conf.cpu().numpy()
                            idx = int(confs.argmax())
                            curr_xyxy = boxes.xyxy[idx].cpu().numpy()  # [x1,y1,x2,y2]

                            if tracked_box is None:
                                tracked_box = curr_xyxy
                                hit_count = 1
                                gap_count = 0
                            else:
                                iou = bbox_iou(tracked_box, curr_xyxy)
                                if iou >= IOU_THRESHOLD:
                                    hit_count += 1
                                    gap_count = 0
                                else:
                                    gap_count += 1
                                    if gap_count > MAX_GAP:
                                        # è®¤ä¸ºåŸæ¥çš„ box ä¸å†ç¨³å®šï¼Œåˆ‡åˆ°æ–° box
                                        tracked_box = curr_xyxy
                                        hit_count = 1
                                        gap_count = 0
                        else:
                            # è¿™ä¸€å¸§æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡
                            if tracked_box is not None:
                                gap_count += 1
                                if gap_count > MAX_GAP:
                                    tracked_box = None
                                    hit_count = 0
                                    gap_count = 0

                        # ========= æ˜¯å¦è¾¾åˆ°ç¨³å®šæ¡ä»¶ =========
                        if tracked_box is not None and hit_count >= MIN_HITS:
                            # è¿™ä¸€å¸§è§¦å‘â€œç¨³å®šäº‹ä»¶â€
                            stable = True          # ğŸ‘‰ è¿™å¸§ stable=Trueï¼ˆè„‰å†²ï¼‰
                            stable_done = True     # æ ‡è®°è¿™ä¸ªå•ç±»å·²ç»è§¦å‘è¿‡

                    # cls_len == 1 ä¸” stable_done == True çš„æƒ…å†µä¸‹ï¼š
                    # è¿™ä¸€æ®µâ€œå•ç±»â€å·²ç»è§¦å‘è¿‡ä¸€æ¬¡äº†ï¼Œä¹‹å stable ä¸€å¾‹ Falseï¼Œ
                    # ç›´åˆ° detect_class æ•°ç»„å˜äº†ï¼ˆä¸Šé¢ class_key != last_class_key ä¼šé‡ç½®ï¼‰ã€‚
                    # cls_len != 1ï¼šYOLO ç…§è·‘ï¼Œä½†ä¸åšç¨³å®šåˆ¤æ–­ï¼Œstable=False



                    # ========= æ˜¾ç¤ºç”»é¢ & è°ƒè¯•æ–‡å­— =========
                    annotated = res[0].plot(conf=False)
                    push_state.latest_frame = annotated
                    if stable:
                        payload = {
                            "type": "cmd",
                            "data": 'raise',
                            "voice_text": str(detect_class[0])
                        }
                        publisher.publish(json.dumps(payload))
                    cv2.putText(
                        annotated,
                        f"cls_len={cls_len}, hits={hit_count}, gaps={gap_count}, "
                        f"stable={int(stable)}, done={int(stable_done)}",
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.8,
                        (0, 255, 0),
                        2,
                    )
                    cv2.imshow("YOLO Stream", annotated)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break

                else:
                    # æœªå¼€å¯æ£€æµ‹ï¼Œç›´æ¥é€ä¼ 
                    if in_frame is not None:
                        # cv2.imshow("YOLO Stream", in_frame)
                        # if cv2.waitKey(1) & 0xFF == ord('q'):
                        #     break
                        push_state.latest_frame = in_frame

    except KeyboardInterrupt:
        print("\n[Main] Exit by user.")
    finally:
        cv2.destroyAllWindows()


